%\begin{landscape}
% Table generated by Excel2LaTeX from sheet 'Sheet 1'
%\begin{table}[htbp]
% \centering
 % \caption{Evaluation and benchmarking articles.}
    \begin{longtable}{p{.15\textwidth}p{.85\textwidth}}
    \caption{Evaluation and benchmarking articles.} \\
    \hline    
    \specialcell{\textbf{Aspect of work}} & \multicolumn{1}{c}{\textbf{Reference/Description}} \\
	\hline
	
	& \multicolumn{1}{c}{\textbf{~\citet{Bramesh2019}}} \\ 
    \specialcell{Details} &
    The performance of state-of-the-art classification methods that utilize vector space, in which terms weighted using weighting methods is compared.      
    \\
    \specialcell{Findings} & 
    The decision tree (C5.0) classifier performed well on all datasets examined.
    \\
    \specialcell{Challenges} & 
    The article should be extended to include other feature selection methods, and to utilize the k-fold validation procedure. 
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Arras2017}}} \\ 
    \specialcell{Details} & 
    The authors demonstrate, based on two classification methods, that understanding of how and why a given classification method classifies can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP).   
    \\
    \specialcell{Findings} & 
	The proposed measure of a modelâ€™s explanatory power depends only on the relevance of words. A CNN model produces better explanations than a BoW/SVM classifier, and incurs lower computational costs. The LRP decomposition method provides better explanations than gradient-based sensitivity analysis. A CNN can take advantage of the word similarity information encoded in the distributed word embeddings.	
	\\
	\specialcell{Challenges} & 
	The suitability of the model should be checked on other neural-based applications, or other types of classification problems, such as sentiment analysis.   
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Mazyad2017}}} \\
    \specialcell{Details} &
    The performance of state-of-the-art classification methods that utilize vector space, in which terms are weighted using feature weighting methods is compared.  
    \\
    \specialcell{Findings} & 
    The superiority of supervised term weighting methods over unsupervised methods remains unclear. 
    \\
    \specialcell{Challenges} & 
    The authors failed to highlight any challenges or open problems.
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Sun2009}}} \\ 
    \specialcell{Details} &
    The performance of state-of-the-art strategies to address imbalanced text classification using SVMs is compared, and a survey of techniques proposed for imbalanced classification is presented.   
    \\
    \specialcell{Findings} & 
    SVMs learn the best decision surface in most test cases. For classification tasks involving high imbalance ratios, it is critical to find an appropriate threshold of SVMs. 
    \\
    \specialcell{Challenges} & 
    Better thresholding strategies should be developed. The learning objective function of the SVMs to consider the data imbalance in learning the decision surface should be improved.
    \\
	
    \hline
    \label{tab:ebm}
    \end{longtable}%
  %\label{tab:addlabel}%
%\end{table}%
%\end{landscape}

%\begin{landscape}
% Table generated by Excel2LaTeX from sheet 'Sheet 1'
%\begin{table}[htbp]
% \centering
 % \caption{Evaluation and benchmarking works.}
    \begin{longtable}{p{.15\textwidth}p{.85\textwidth}}
    \caption{Evaluation and benchmarking works.} \\
    \hline    
    \specialcell{\textbf{Aspect of work}} & \multicolumn{1}{c}{\textbf{Reference/Description}} \\
	\hline
	
	& \multicolumn{1}{c}{\textbf{~\citet{Bramesh2019}}} \\ 
    \specialcell{Details} &
    The performance of state of the art classification methods that utilise vector space where terms are weighting thanks to using weighting methods is compared.      
    \\
    \specialcell{Findings} & 
    The decision tree (C5.0) classifier has performed well on all stated datasets.
    \\
    \specialcell{Challenges} & 
    The work should be extended to include other feature selection methods and to use the k-fold validation procedure. 
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Arras2017}}} \\ 
    \specialcell{Details} & 
    The authors demonstrated, based on two classification methods, that understanding of how and why the given classification method classify can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP).   
    \\
    \specialcell{Findings} & 
	The proposed measure of model explanatory power depend only on the word relevances. The Convolutional Neural Network (CNN) model produces better explanations than the BoW/SVM classifier and presents better computational costs. The LRP decomposition method provides better explanations than gradient-based sensitivity analysis (SA). The CNN can take advantage of the word similarity information encoded in the distributed word embeddings.	
	\\
	\specialcell{Challenges} & 
	The suitable of the model should be checked on other neural-based applications or other types of classification problems (e.g. sentiment analysis).   
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Mazyad2017}}} \\
    \specialcell{Details} &
    The performance of state of the art classification methods that utilise vector space where terms are weighting thanks to using feature weighting methods is compared.  
    \\
    \specialcell{Findings} & 
    The superiority of supervised term weighting methods over unsupervised methods is still not clear. 
    \\
    \specialcell{Challenges} & 
    The authors do not highlighted challenges or open problems.
	\\
	
	& \multicolumn{1}{c}{\textbf{~\citet{Sun2009}}} \\ 
    \specialcell{Details} &
    The performance of state of the art strategies addressing imbalanced text classification using Support Vector Machines (SVMs) is compared, and the survey of techniques proposed for imbalanced classification is presented.   
    \\
    \specialcell{Findings} & 
    The SVM often learn the best decision surface in most test cases. For the classification tasks involving high imbalance ratios, it is critical to find an appropriate threshold of SVMs. 
    \\
    \specialcell{Challenges} & 
    The better thresholding strategies should be developed. The SVMs learning objective function to consider the data imbalance in learning the decision surface should be improved.
    \\
	
    \hline
     \label{tab:ebm}
    \end{longtable}%
  %\label{tab:addlabel}%
%\end{table}%
%\end{landscape}